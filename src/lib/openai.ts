import OpenAI from 'openai';
import { VisionRecognitionResult } from './types';

// Initialize OpenAI client
const client = new OpenAI({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  dangerouslyAllowBrowser: true, // Required for client-side usage
});

/**
 * Analyzes a game result image and extracts player information
 * @param imageBase64 - Base64 encoded image string
 * @returns Promise containing player information and recognition confidence
 */
export async function analyzeGameImage(
  imageBase64: string
): Promise<VisionRecognitionResult> {
  const prompt = `
åˆ†æé€™å¼µæ²™ä¸˜æ¡ŒéŠçš„çµç®—åœ–ç‰‡ï¼Œæå–ä»¥ä¸‹è³‡è¨Šã€‚
è«‹ä»¥JSONæ ¼å¼è¿”å›ï¼š
{
  "players": [
    {
      "name": "ç©å®¶åç¨±",
      "faction": "è§’è‰²ä¸­æ–‡åç¨±",
      "score": åˆ†æ•¸(æ•¸å­—),
      "isWinner": æ˜¯å¦å‹åˆ©(å¸ƒæ—å€¼)
    }
  ],
  "confidence": è­˜åˆ¥ä¿¡å¿ƒåº¦(0-1)
}

è§’è‰²åç¨±å¿…é ˆä½¿ç”¨ä¸­æ–‡ï¼Œå¾ä»¥ä¸‹é¸æ“‡ï¼š
- äºå´”è¿ªï¼ˆAtreidesï¼‰
- å“ˆè‚¯èƒ½ï¼ˆHarkonnenï¼‰
- çš‡å¸ï¼ˆEmperorï¼‰
- å¼—é›·æ›¼ï¼ˆFremenï¼‰
- è²å°¼Â·å‚‘ç‘Ÿé‡Œç‰¹ï¼ˆBene Gesseritï¼‰
- é–“è¡Œæœƒï¼ˆSpacing Guildï¼‰
- æ¢…è¾²Â·ç´¢ç“¦çˆ¾å¾·ä¼¯çˆµï¼ˆCount Memnon Thorvaldï¼‰
- æµ·å€«å¨œÂ·é‡Œå¥‡æ–¯ï¼ˆHelena Richeseï¼‰
- æ ¼ç¾…è˜‡Â·æ‹‰ç­ï¼ˆGlossu Rabbanï¼‰

æœ€é«˜åˆ†è€…ç‚ºå‹åˆ©è€…ã€‚ç„¡æ³•è­˜åˆ¥çš„æ¬„ä½ç”¨nullã€‚
è«‹åªè¿”å› JSONï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—èªªæ˜ã€‚
`;

  try {
    console.log('ğŸ¤– Calling OpenAI Vision API...');
    console.log('ğŸ“ API Key configured:', !!import.meta.env.VITE_OPENAI_API_KEY);
    console.log('ğŸ–¼ï¸ Image size (base64):', Math.round(imageBase64.length / 1024), 'KB');

    const response = await client.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        {
          role: 'user',
          content: [
            { type: 'text', text: prompt },
            {
              type: 'image_url',
              image_url: {
                url: `data:image/jpeg;base64,${imageBase64}`,
              },
            },
          ],
        },
      ],
      max_tokens: 500,
      temperature: 0.3, // Lower temperature for consistent JSON output
    });

    console.log('âœ… OpenAI API response received');
    console.log('ğŸ“Š Response:', response);

    const content = response.choices[0]?.message?.content;
    if (!content) {
      console.error('âŒ No content in response');
      throw new Error('No response from OpenAI');
    }

    console.log('ğŸ“„ Response content:', content);

    // å»é™¤ markdown ä»£ç¢¼å¡Šæ¨™è¨˜ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    let cleanedContent = content.trim();

    // ç§»é™¤ ```json å’Œ ``` æ¨™è¨˜
    if (cleanedContent.startsWith('```json')) {
      cleanedContent = cleanedContent.replace(/^```json\s*\n?/, '');
    } else if (cleanedContent.startsWith('```')) {
      cleanedContent = cleanedContent.replace(/^```\s*\n?/, '');
    }

    if (cleanedContent.endsWith('```')) {
      cleanedContent = cleanedContent.replace(/\n?```$/, '');
    }

    console.log('ğŸ§¹ Cleaned content:', cleanedContent);

    // Parse JSON response
    const result = JSON.parse(cleanedContent) as VisionRecognitionResult;
    console.log('âœ… Parsed result:', result);
    return result;
  } catch (error) {
    console.error('âŒ OpenAI Vision API error:', error);
    if (error instanceof Error) {
      console.error('Error message:', error.message);
      console.error('Error stack:', error.stack);
    }
    throw new Error('Failed to analyze image. Please try again or enter data manually.');
  }
}

export { client };
export default client;
